{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#需要的包一股脑全放里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2,urllib,sys,os\n",
    "import codecs,re,string,json\n",
    "from subprocess import *\n",
    "from collections import Counter\n",
    "import mdptoolbox\n",
    "from numpy  import *\n",
    "import aiml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#分词标注部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def divPos(input):\n",
    "    uri_base = \"http://api.ltp-cloud.com/analysis/\"\n",
    "    api_key  = \"98H7b393hUPX5tQwEgXwpgPc6m0c1jLTVgJkJymu\" \n",
    "    text= urllib.quote(input)\n",
    "    #语言云的真正调用方法    \n",
    "    uri_base = \"http://api.ltp-cloud.com/analysis/\"       \n",
    "    data = {\n",
    "            \"api_key\"   : \"98H7b393hUPX5tQwEgXwpgPc6m0c1jLTVgJkJymu\",\n",
    "            \"text\"      : text,\n",
    "            \"format\"    : \"json\",\n",
    "            \"has_key\"   : \"false\",\n",
    "            \"pattern\"   : \"pos\",               \n",
    "\n",
    "            }\n",
    "    params = urllib.urlencode(data)\n",
    "    try:\n",
    "        request  = urllib2.Request(uri_base)\n",
    "        response = urllib2.urlopen(request, params)\n",
    "        content  = response.read().strip()\n",
    "        \n",
    "        return content \n",
    "    except urllib2.HTTPError, e:\n",
    "        print >> sys.stderr, e.reason\n",
    "#json格式转化成plain格式\n",
    "def jsonToPlain(contentJson):\n",
    "    #只保留分词和标注输出\n",
    "    #posResult=[word for word in sentence[0] for sentence in content for ]\n",
    "    resultList=[]\n",
    "    for paragraph in contentJson:\n",
    "        sentenceList=[]\n",
    "        if paragraph[0][-1][-1]== \"wp\":\n",
    "            sent=paragraph[0][:-1]\n",
    "        else:\n",
    "            sent=paragraph[0]\n",
    "        length=len(sent)\n",
    "        wordIndex=0\n",
    "        while wordIndex<length:\n",
    "            if u\"转\" in sent[wordIndex][1]:\n",
    "                sent[wordIndex][2]=\"v\"\n",
    "            if wordIndex+2<len(sent) and u\"q\" == sent[wordIndex][2] and u\"每\" == sent[wordIndex+1][1] and u\"q\" == sent[wordIndex+2][2]:\n",
    "                merge=[wordIndex,sent[wordIndex][1]+sent[wordIndex+1][1]+sent[wordIndex+2][1],sent[wordIndex][2]]\n",
    "                sent=sent[:wordIndex]+[merge]+sent[wordIndex+3:]\n",
    "                length=len(sent)\n",
    "            sentenceList.append(sent[wordIndex][1]+'\\t'+sent[wordIndex][2])\n",
    "            wordIndex+=1\n",
    "        sentence='\\n'.join(sentenceList).encode('utf-8')\n",
    "        sentence1=re.sub( r'(nh|ni|nl|ns|nz)' , 'n' , sentence )\n",
    "        resultList.append(sentence1+'\\n'*2)\n",
    "\n",
    "    return resultList\n",
    "\n",
    "#分词调用程序\n",
    "def distinguishWord():\n",
    "    #测试句子，直接输入\n",
    "    dataa=raw_input('输入命令：'.decode('utf-8')).decode('gb2312').encode('utf-8')#程序中字符串为utf-8，交互中键盘敲入为gb2312\n",
    "    #输入句子，调用分词标注函数，输出结果（json）\n",
    "    if dataa=='':\n",
    "        return False\n",
    "    f0=open('allTest','a')\n",
    "    f0.write(dataa+\"\\n\")\n",
    "    f0.close()\n",
    "    output=divPos(dataa)\n",
    "\n",
    "    #将分词标注结果输出到txt文档中\n",
    "    f1=open('distinguishWordJson','w')\n",
    "    f1.write(output)\n",
    "    f1.close()\n",
    "    \n",
    "    contentJson=json.loads(output)\n",
    "\n",
    "    resultList=jsonToPlain(contentJson)\n",
    "    f2=open('distinguishWordPlain','w')\n",
    "    f2.writelines(resultList)\n",
    "    f2.close()\n",
    "    \n",
    "    return True\n",
    "\n",
    "def save():\n",
    "    \n",
    "    f6=open('semanticOutput','r')\n",
    "    output1=f6.read()\n",
    "    f6.close()    \n",
    "    \n",
    "    f7=open('splitOutput','r')\n",
    "    output2=f7.read()\n",
    "    f7.close() \n",
    "    \n",
    "    f8=open('savesemanticOutput','a')\n",
    "    f8.write(output1)\n",
    "    f8.close()\n",
    "    \n",
    "    f9=open('savesplitOutput','a')\n",
    "    f9.write(output2)\n",
    "    f9.close()\n",
    "    \n",
    "\n",
    "def train(template,trainTxt,model):      \n",
    "    #returnCode = call('crf_learn.exe template crfTrain1.txt model1')\n",
    "    call('crf_learn.exe '+template+' '+trainTxt+' '+ model)\n",
    "def test(model,testTxt,testOutput):\n",
    "    \"\"\"\n",
    "    -v1:输出标签的概率值\n",
    "    -n :输出几层不同概率只的选项 用处不大\n",
    "    -t:输出model的txt版本\n",
    "    -f：是一阀值，只有某词的频率大于该值 才有用\n",
    "    -c：跟拟合度有关的一个参数\n",
    "    -h: 可以随时打开帮助看看\n",
    "    \n",
    "    \"\"\"\n",
    "    #Popen('crf_test.exe -m model1 crfTest1.txt >output1.txt', shell = True, stdout = PIPE).stdout\n",
    "    Popen('crf_test.exe -m '+model+' '+ testTxt +'>'+testOutput, shell = True, stdout = PIPE).communicate()\n",
    "    #Popen('crf_test.exe -m '+model+' '+ testTxt +'>'+testOutput, shell = True, stdout = PIPE).communicate()\n",
    "def evaluate(testOutput,testResult):\n",
    "    \n",
    "    evalue=Popen('conlleval.pl -d \"\\t\" -r < '+testOutput+' > '+testResult,\n",
    "                 shell = True, stdout = PIPE).stdout\n",
    "    #https://argcv.com/articles/2104.c#respond   参考资料，参数使用很全\n",
    "    #print evalue.read()\n",
    "\n",
    "def semanticTrain():#http://www.hankcs.com/nlp/the-crf-model-format-description.html  不错的资料\n",
    "    train('semanticTemplate','semanticTrain','semanticModel')\n",
    "def semanticTest():\n",
    "    test('semanticModel','distinguishWordPlain','semanticOutput')\n",
    "    #test('model','crfTest1.txt','output1.txt')\n",
    "\n",
    "def semanticEvaluate():\n",
    "    evaluate('semanticEvaluate','semanticEvaluateOutput')\n",
    "    \n",
    "\n",
    "\n",
    "#将普通的字符串格式的输入转化成json列表形式\n",
    "def plainToJson(semanticOutput):\n",
    "    fCrfTrain=open(semanticOutput,'r')\n",
    "    article=fCrfTrain.read()\n",
    "    if article[:3] == codecs.BOM_UTF8:\n",
    "            article = article[3:]  \n",
    "    fCrfTrain.close()\n",
    "\n",
    "    sentenceLabel=re.compile(r\"(.*?)\\n\\n\",re.S)\n",
    "    sentenceList=re.findall(sentenceLabel,article)\n",
    "\n",
    "    #print sentenceList[0:10]\n",
    "\n",
    "    wordListInSentenceList=[]\n",
    "    for sentence in sentenceList:\n",
    "        wordList=sentence.split('\\n')\n",
    "        wordPosYuyiList=[]\n",
    "        for word in wordList:\n",
    "            wordPosYuyi=word.split('\\t')\n",
    "            wordPosYuyiList.append(wordPosYuyi)\n",
    "        wordListInSentenceList.append(wordPosYuyiList)\n",
    "    return wordListInSentenceList\n",
    "#普通的字符串格式的输入（带有边缘概率需要处理）转化成json列表形式\n",
    "def proPlainToJson(semanticOutput):\n",
    "    fCrfTrain=open(semanticOutput,'r')\n",
    "    article=fCrfTrain.read()\n",
    "    if article[:3] == codecs.BOM_UTF8:\n",
    "            article = article[3:]  \n",
    "    fCrfTrain.close()\n",
    "\n",
    "    sentenceLabel=re.compile(r\"(.*?)\\n\\n\",re.S)\n",
    "    sentenceList=re.findall(sentenceLabel,article)\n",
    "\n",
    "    #print sentenceList[0:10]\n",
    "\n",
    "    wordListInSentenceList=[]\n",
    "    for sentence in sentenceList:\n",
    "        wordList=sentence.split('\\n')\n",
    "        \n",
    "        wordPosYuyiProList=[]\n",
    "        for word in wordList[1:]:\n",
    "            wordPosYuyiPro=word.split('\\t')\n",
    "            newWordPosYuyiPro=wordPosYuyiPro[:-1]+[wordPosYuyiPro[-1].split('/')[0]]\n",
    "            wordPosYuyiProList.append(newWordPosYuyiPro)\n",
    "        wordListInSentenceList.append([float(wordList[0][2:])]+wordPosYuyiProList)\n",
    "    return wordListInSentenceList\n",
    "#将名词和方向词合并 输出json格式\n",
    "def n_f(wordListInSentenceList):\n",
    "    for s in xrange(len(wordListInSentenceList)):\n",
    "        wordPosition=0\n",
    "        while wordPosition<len(wordListInSentenceList[s]):\n",
    "            nPosition=[]\n",
    "            while wordPosition<len(wordListInSentenceList[s]) and '-Place' in wordListInSentenceList[s][wordPosition][-1]:\n",
    "                \n",
    "                nPosition.append(wordPosition)\n",
    "                wordPosition+=1\n",
    "            #print nPosition \n",
    "            if len(nPosition)!=0:\n",
    "                #\n",
    "                words=[]\n",
    "                for p in nPosition:\n",
    "                    words.append(wordListInSentenceList[s][p][0])\n",
    "                word=''.join(words)\n",
    "                nTotal=[word,'n','Place']\n",
    "                wordListInSentenceList[s]=wordListInSentenceList[s][:nPosition[0]]+[nTotal]+wordListInSentenceList[s][nPosition[-1]+1:]\n",
    "                #print wordListInSentenceList[s]\n",
    "                wordPosition=nPosition[0]\n",
    "            \n",
    "            aPosition=[]\n",
    "            while wordPosition<len(wordListInSentenceList[s]) and '-AT' in wordListInSentenceList[s][wordPosition][-1]:\n",
    "                \n",
    "                aPosition.append(wordPosition)\n",
    "                wordPosition+=1\n",
    "            #print nPosition \n",
    "            if len(aPosition)!=0:\n",
    "                #\n",
    "                words=[]\n",
    "                for a in aPosition:\n",
    "                    words.append(wordListInSentenceList[s][a][0])\n",
    "                word=''.join(words)\n",
    "                aTotal=[word,'a','AT']\n",
    "                wordListInSentenceList[s]=wordListInSentenceList[s][:aPosition[0]]+[aTotal]+wordListInSentenceList[s][aPosition[-1]+1:]\n",
    "                #print wordListInSentenceList[s]\n",
    "                wordPosition=aPosition[0]\n",
    "                                        \n",
    "            naPosition=[]\n",
    "            while wordPosition<len(wordListInSentenceList[s]) and '-NAT' in wordListInSentenceList[s][wordPosition][-1]:\n",
    "                \n",
    "                naPosition.append(wordPosition)\n",
    "                wordPosition+=1\n",
    "            #print nPosition \n",
    "            if len(naPosition)!=0:\n",
    "                #\n",
    "                words=[]\n",
    "                for na in naPosition:\n",
    "                    words.append(wordListInSentenceList[s][na][0])\n",
    "                word=''.join(words)\n",
    "                naTotal=[word,'a','NAT']\n",
    "                wordListInSentenceList[s]=wordListInSentenceList[s][:naPosition[0]]+[naTotal]+wordListInSentenceList[s][naPosition[-1]+1:]\n",
    "                #print wordListInSentenceList[s]\n",
    "                wordPosition=naPosition[0]\n",
    "                    \n",
    "            vPosition=[]\n",
    "            while wordPosition<len(wordListInSentenceList[s]) and '-DurativeVerb' in wordListInSentenceList[s][wordPosition][-1]:\n",
    "                \n",
    "                vPosition.append(wordPosition)\n",
    "                wordPosition+=1\n",
    "            #print nPosition \n",
    "            if len(vPosition)!=0:\n",
    "                #\n",
    "                words=[]\n",
    "                for v in vPosition:\n",
    "                    words.append(wordListInSentenceList[s][v][0])\n",
    "                word=''.join(words)\n",
    "                vTotal=[word,'v','DurativeVerb']\n",
    "                wordListInSentenceList[s]=wordListInSentenceList[s][:vPosition[0]]+[vTotal]+wordListInSentenceList[s][vPosition[-1]+1:]\n",
    "                #print wordListInSentenceList[s]\n",
    "                wordPosition=vPosition[0]\n",
    "                \n",
    "            fPosition=[]\n",
    "            while wordPosition<len(wordListInSentenceList[s]) and '-Direction' in wordListInSentenceList[s][wordPosition][-1]:\n",
    "                \n",
    "                fPosition.append(wordPosition)\n",
    "                wordPosition+=1\n",
    "            #print nPosition \n",
    "            if len(fPosition)!=0:\n",
    "                #\n",
    "                words=[]\n",
    "                for p in fPosition:\n",
    "                    words.append(wordListInSentenceList[s][p][0])\n",
    "                word=''.join(words)\n",
    "                fTotal=[word,'nd','Direction']\n",
    "                wordListInSentenceList[s]=wordListInSentenceList[s][:fPosition[0]]+[fTotal]+wordListInSentenceList[s][fPosition[-1]+1:]\n",
    "                #print wordListInSentenceList[s]\n",
    "                wordPosition=fPosition[0]\n",
    "            #print wordPosition\n",
    "            wordPosition+=1\n",
    "    return\n",
    "\n",
    "#将合并后的json格式转化成plain格式输出    \n",
    "def jsonToPlain1(contentJson):\n",
    "    #只保留分词和标注输出\n",
    "    #posResult=[word for word in sentence[0] for sentence in content for ]\n",
    "    resultList=[]\n",
    "    for paragraph in contentJson:\n",
    "        sentenceList=[]\n",
    "        for word in paragraph:\n",
    "            sentenceList.append(word[0]+'\\t'+word[1]+'\\t'+word[2])\n",
    "        sentence='\\n'.join(sentenceList)\n",
    "        resultList.append(sentence+'\\n'*2)\n",
    "    return resultList\n",
    "\n",
    "def merge():\n",
    "    wordListInSentenceList=plainToJson('semanticOutput')#crfTrain.txt  包含词  词性  语义 的plain文件\n",
    "    n_f(wordListInSentenceList)\n",
    "\n",
    "\n",
    "    data=json.dumps(wordListInSentenceList)\n",
    "    f3=open('n_f_outputTestJson','w')                #jsonData.txt对应crfTrain的合并结果\n",
    "    f3.writelines(data)\n",
    "    f3.close()\n",
    "\n",
    "    result=jsonToPlain1(wordListInSentenceList)\n",
    "    f4=open('n_f_outputTest','w')           #n_f.data对应jsonData.txt  plain格式\n",
    "    f4.writelines(result)\n",
    "    f4.close()\n",
    "    \n",
    "#所有句子的特征列表\n",
    "def sentProperty(listData):\n",
    "    property_all=[]\n",
    "    for sentence in listData:\n",
    "        #句子中的语义列表\n",
    "        yuyiList=[ word[-1] for word in sentence]\n",
    "        yuyiStr=' '+' '.join(yuyiList)\n",
    "        #除0外的词占句子的比例\n",
    "        property1=1-Counter(yuyiList)['Other']/len(yuyiList)\n",
    "        #是否有动词\n",
    "        property2=1 if re.search(r'DurativeVerb|MomentaryVerb',yuyiStr) else 0\n",
    "        \n",
    "        #是否含有方向词\n",
    "        property3=1 if 'Direction' in yuyiList else 0\n",
    "        #是否含有地名词\n",
    "        property4=1 if 'Place' in yuyiList else 0\n",
    "        #是否含有数词加量词的集合\n",
    "        property5=1 if  re.search(r'Num DistanceUnit',yuyiStr)  else 0\n",
    "        #方向词加动词的个数\n",
    "        property6=len(re.findall(r'Direction (DurativeVerb|MomentaryVerb)',yuyiStr))\n",
    "        #动词加地名词的个数\n",
    "        property7=len(re.findall(r'(DurativeVerb|MomentaryVerb) Place',yuyiStr))\n",
    "        #地名词加动词\n",
    "        property8=len(re.findall(r'Place (DurativeVerb|MomentaryVerb)',yuyiStr))\n",
    "        #动词的个数\n",
    "        property9=len(re.findall(r'(DurativeVerb|MomentaryVerb)',yuyiStr))\n",
    "        #关键词类别个数占句子长度的比例\n",
    "        property10=len(set(yuyiList))/len(yuyiList)\n",
    "        \n",
    "        property_all.append([property1,property2,property3,property4,property5,property6,property7,property8,property9,property10])\n",
    "    return property_all\n",
    "\n",
    "#给每个句子贴上1或-1的标签，自己标出来\n",
    "def label_initialize():\n",
    "    set_label_1=[1]*60\n",
    "    label_0=[7,53,54,55,56,57,58,59]\n",
    "    for label in label_0:\n",
    "        set_label_1[label]=-1\n",
    "    return set_label_1\n",
    "\n",
    "#将句子的特征和1、-1标签弄成svm的输入格式\n",
    "def svm_input(property_all,label_tag):\n",
    "    svm_format=[]\n",
    "    for index in xrange(len(property_all)):               \n",
    "        column=str(label_tag[index])\n",
    "        for property_index in xrange(len(property_all[index])):\n",
    "            column+='\\t'+str(property_index+1)+':'+str(property_all[index][property_index])   \n",
    "        svm_format.append(column+'\\n')\n",
    "    return svm_format\n",
    "\n",
    "def svmProperty(n_f_input):\n",
    "#从合并后的带有语义标注的预料中  提取出svm的特征向量  以及自己标注的标签 存放在一个文本文档中\n",
    "    f5=open(n_f_input,'r')  #jsonData\n",
    "    jsonData1=f5.read()\n",
    "    f5.close()\n",
    "    listData=json.loads(jsonData1)\n",
    "    sentPropertyAll=sentProperty(listData)\n",
    "\n",
    "    #sentLabel=label_initialize()\n",
    "    #sentLabel=[0]*len(sentPropertyAll)\n",
    "    \n",
    "    return sentPropertyAll\n",
    "\n",
    "#训练模型  \n",
    "def svmTrain():\n",
    "    sentPropertyAll=svmProperty('jsonData')\n",
    "    sentLabel=label_initialize()\n",
    "    m=svm_train(sentLabel,sentPropertyAll,'-c 4')\n",
    "    svm_save_model('svmModel', m)\n",
    "    \n",
    "#进行测试\n",
    "def svmTest():\n",
    "    #y,x=svm_read_problem('svm_input_test.txt')\n",
    "    x=svmProperty('n_f_outputTestJson')\n",
    "    y=[0]*len(x)\n",
    "    m = svm_load_model('svmModel')\n",
    "    p_label,p_acc,p_val=svm_predict(y,x,m)\n",
    "    return p_label\n",
    "\n",
    "def splitTrain():\n",
    "    train('splitTemplate','splitTrain','splitModel')\n",
    "\n",
    "def splitTest():\n",
    "    test('splitModel','n_f_outputTest','splitOutput')\n",
    "def startFinishTrain():\n",
    "    train('startFinishTemplate','startFinishTrain','startFinishmodel')\n",
    "def startFinishTest():\n",
    "    test('startFinishmodel','splitOutput','startFinishOutput')\n",
    "\n",
    "def isanum(str):\n",
    "    try:\n",
    "        float(str)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "digitDict ={u'零':0, u'一':1, u'二':2, u'三':3, u'四':4, u'五':5, u'六':6, u'七':7, u'八':8, u'九':9, u'十':10, u'百':100, u'千':1000, \n",
    "       u'万':10000,u'亿':100000000,u'０':0, u'1':1, u'2':2, u'3':3, u'4':4, u'5':5, u'6':6, u'7':7, u'8':8, u'9':9}\n",
    "def getResultForDigit(a, encoding=\"utf-8\"):\n",
    "    if isinstance(a, str):\n",
    "        a = a.decode(encoding)\n",
    "    count = 0 \n",
    "    result = 0\n",
    "    tmp = 0\n",
    "    Billion = 0  \n",
    "    while count < len(a):\n",
    "        tmpChr = a[count]\n",
    "        tmpNum = digitDict.get(tmpChr, None)\n",
    "        #如果等于1亿\n",
    "        if tmpNum == 100000000:\n",
    "            result = result + tmp\n",
    "            result = result * tmpNum\n",
    "            #获得亿以上的数量，将其保存在中间变量Billion中并清空result\n",
    "            Billion = Billion * 100000000 + result \n",
    "            result = 0\n",
    "            tmp = 0\n",
    "        #如果等于1万\n",
    "        elif tmpNum == 10000:\n",
    "            result = result + tmp\n",
    "            result = result * tmpNum\n",
    "            tmp = 0\n",
    "        #如果等于十或者百，千\n",
    "        elif tmpNum >= 10:\n",
    "            if tmp == 0:\n",
    "                tmp = 1\n",
    "            result = result + tmpNum * tmp\n",
    "            tmp = 0\n",
    "        #如果是个位数\n",
    "        elif tmpNum is not None:\n",
    "            tmp = tmp * 10 + tmpNum\n",
    "        count += 1\n",
    "    result = result + tmp\n",
    "    result = result + Billion\n",
    "    return result\n",
    "\n",
    "def extract(output):\n",
    "    wordList=plainToJson(output)[0]\n",
    "    splitWordList=[]\n",
    "    beginLabel=[]\n",
    "    for i in xrange(len(wordList)):\n",
    "        if 'B' in wordList[i][3]:\n",
    "            beginLabel.append(i)\n",
    "    beginLabel.append(len(wordList))\n",
    "    \n",
    "    for i in xrange(len(beginLabel)-1):\n",
    "        splitWordList.append(wordList[beginLabel[i]:beginLabel[i+1]])\n",
    "    #print splitWordList\n",
    "    structureList=[]\n",
    "    for unit in splitWordList:\n",
    "        structure=['__']*7\n",
    "        for i in xrange(len(unit)):\n",
    "            if unit[i][-1]=='s': \n",
    "                structure[0]=unit[i][0]\n",
    "            if unit[i][-1]=='f':\n",
    "                structure[1]=unit[i][0]\n",
    "            if 'Place' in unit[i][2]:\n",
    "                structure[1]=unit[i][0]\n",
    "            if 'DurativeVerb' in unit[i][2]:\n",
    "                structure[2]=unit[i][0]\n",
    "            elif unit[i][2]=='MomentaryVerb':\n",
    "                structure[2]=unit[i][0]\n",
    "            if unit[i][2]=='Direction':\n",
    "                structure[3]=unit[i][0]\n",
    "            if unit[i][2]=='Num' and i<len(unit)-1 and unit[i+1][2]=='DistanceUnit':            \n",
    "                if  isanum(unit[i][0]):\n",
    "                    digit=unit[i][0]\n",
    "                else:\n",
    "                    digit=str(getResultForDigit(unit[i][0]))\n",
    "                    if digit=='0'or unit[i+1][0]==\"点\" or unit[i+1][0]==\"些\":\n",
    "                        digit=unit[i][0]\n",
    "                if unit[i+1][0]=='厘米' or unit[i+1][0]=='公分':\n",
    "                    structure[4]=str(float(digit)/100)\n",
    "                elif unit[i+1][0]=='分米':\n",
    "                    structure[4]=str(float(digit)/10)\n",
    "                elif unit[i+1][0]=='米':\n",
    "                    structure[4]=digit\n",
    "                else:\n",
    "                    structure[4]=digit+unit[i+1][0]\n",
    "            if unit[i][2]=='Distance':\n",
    "                structure[4]=unit[i][0]\n",
    "            if unit[i][2]=='Speed':\n",
    "                structure[5]=unit[i][0]\n",
    "            if unit[i][2]=='Num' and i<len(unit)-1 and unit[i+1][2]=='SpeedUnit':\n",
    "                if  isanum(unit[i][0]):\n",
    "                    digit=unit[i][0]\n",
    "                else:\n",
    "                    digit=str(getResultForDigit(unit[i][0]))\n",
    "                    if digit=='0'or unit[i+1][0]==\"点\" or unit[i+1][0]==\"些\":\n",
    "                        digit=unit[i][0]\n",
    "                if unit[i+1][0]=='厘米每秒' or unit[i+1][0]=='公分每秒':\n",
    "                    structure[5]=str(float(digit)/100)\n",
    "                elif unit[i+1][0]=='分米每秒':\n",
    "                    structure[5]=str(float(digit)/10)\n",
    "                elif unit[i+1][0]=='米每秒':\n",
    "                    structure[5]=digit\n",
    "                elif unit[i+1][0]=='迈' or unit[i+1][0]=='码':\n",
    "                    structure[5]=str(float(digit)*0.278)\n",
    "                else:\n",
    "                    structure[5]=digit+unit[i+1][0]\n",
    "            if unit[i][2]=='AT':\n",
    "                structure[6]=unit[i][2]\n",
    "            if unit[i][2]=='NAT':\n",
    "                structure[6]=unit[i][2]\n",
    "        structureList.append(structure)\n",
    "        \n",
    "        for structure in structureList:\n",
    "             print ','.join(structure)\n",
    "    return structureList\n",
    "\n",
    "def fillElement(structureList):#提取结构化指令之后的要素规范化\n",
    "    for i in range(len(structureList)):\n",
    "        if structureList[i][0]=='__':\n",
    "            if i != 0 and structureList[i-1][1] !='__':\n",
    "                structureList[i][0]=structureList[i-1][1]\n",
    "            else:\n",
    "                structureList[i][0]='当下位置'\n",
    "        #if \"停\" in structureList[i][2] or \"头\" in structureList[i][2]:\n",
    "            #continue\n",
    "        #if structureList[i][4]=='__':\n",
    "        #if \"快\" or \"加\" in structureList[i][5]:\n",
    "            #structureList[i][5]=\"加速\"\n",
    "            #continue\n",
    "        #if \"慢\" or \"减\" in structureList[i][5]:\n",
    "            #structureList[i][5]=\"减速\"\n",
    "            #continue\n",
    "        if i !=len(structureList)-1 and structureList[i+1][0] !='__':\n",
    "            structureList[i][1]=structureList[i+1][0]\n",
    "        #if structureList[i][2]=='__':\n",
    "            #if i !=0:\n",
    "                #structureList[i][2]=structureList[i-1][2]\n",
    "            #else:\n",
    "                #structureList[i][2]='走'\n",
    "        #if \"去\" in structureList[i][2] or \"到\" in structureList[i][2]:\n",
    "            #structureList[i][2]='前'\n",
    "        if structureList[i][2]!='__' or structureList[i][2]!='__':\n",
    "            if \"后\" in structureList[i][3] or \"后\" in structureList[i][2]:\n",
    "                structureList[i][2]='后'\n",
    "            if \"前\" in structureList[i][3] or \"前\" in structureList[i][2]:\n",
    "                structureList[i][2]='前'\n",
    "            if \"左\" in structureList[i][3] or \"左\" in structureList[i][2]:\n",
    "                structureList[i][2]='左'\n",
    "            if \"右\" in structureList[i][3] or \"右\" in structureList[i][2]:\n",
    "                structureList[i][2]='右'\n",
    "        if structureList[i][4]!='__':\n",
    "            structureList[i][4]=structureList[i][4]+'米'\n",
    "        \n",
    "        if \"停\" in structureList[i][2]:\n",
    "            structureList[i][2]=\"停\"\n",
    "        \n",
    "        if \"退\" in structureList[i][2]:\n",
    "            structureList[i][2]=\"退\"\n",
    "    \n",
    "        if \"拧\" in structureList[i][2] or \"开\" in structureList[i][2]:\n",
    "            #structureList[i][1]=structureList[i][2].replace(\"开\",\"\").replace(\"拧\",\"\")\n",
    "            structureList[i][2]=\"打开\"\n",
    "            \n",
    "        if \"头\" in structureList[i][2] or \"转身\" in structureList[i][2]:\n",
    "            structureList[i][2]=\"掉头\"\n",
    "            \n",
    "        if \"到\" in structureList[i][2] or \"去\" in structureList[i][2]:\n",
    "            structureList[i][2]=\"到\"\n",
    "            \n",
    "        if \"推\" in structureList[i][2]:\n",
    "            structureList[i][2]=\"推\"\n",
    "\n",
    "        if \"搬\" in structureList[i][2]:\n",
    "            structureList[i][2]=\"搬\"\n",
    "            \n",
    "        if \"拿\" in structureList[i][2]:\n",
    "            structureList[i][2]=\"拿\"\n",
    "\n",
    "        if \"抬\" in structureList[i][2]:\n",
    "            structureList[i][2]=\"抬\"\n",
    "            \n",
    "        if (\"拍\" in structureList[i][2] or \"看\" in structureList[i][2]) and structureList[i][1]=='__':\n",
    "            structureList[i][1]=structureList[i][2].replace(\"拍\",\"\")\n",
    "            structureList[i][2]=\"拍\"\n",
    "        \n",
    "        if \"录\" in structureList[i][2] and structureList[i][1]=='__':\n",
    "            structureList[i][1]=structureList[i][2].replace(\"录\",\"\")\n",
    "            structureList[i][2]=\"录\"\n",
    "            \n",
    "        if \"采集\" in structureList[i][2]:\n",
    "            structureList[i][2]=\"采集\"\n",
    "        \n",
    "        if structureList[i][2]=='__' and structureList[i][1]!='__':\n",
    "            structureList[i][2]='到'   \n",
    "        if \"画\" in structureList[i][1] or \"图\" in structureList[i][1] or \"照\" in structureList[i][1]:\n",
    "            structureList[i][1]=\"照片\"\n",
    "        \n",
    "        #if structureList[i][3]=='__' and structureList[i][1]=='__':\n",
    "            #动作中含有方向\n",
    "            #if \"后\" in structureList[i][3]:\n",
    "                #structureList[i][3]='后'\n",
    "                #structureList[i][2]='后'\n",
    "            #elif \"左\" in structureList[i][3]:\n",
    "                #structureList[i][3]='左'\n",
    "                #structureList[i][2]='左'\n",
    "            #elif \"右\" in structureList[i][3]:\n",
    "                #structureList[i][3]='右'\n",
    "                #structureList[i][2]='右'\n",
    "            #else:\n",
    "                #structureList[i][3]='前'\n",
    "                #structureList[i][2]='前'\n",
    "        #动作中含有速度\n",
    "        #if structureList[i][0]=='__':\n",
    "            #if \"快\" in structureList[i][2] or \"急\" in structureList[i][2]:\n",
    "                #structureList[i][5]='加速'\n",
    "            #elif \"慢\" in structureList[i][2] or \"缓\" in structureList[i][2]:\n",
    "                #structureList[i][5]='减速'\n",
    "        \n",
    "        #if structureList[i][2]!='__':\n",
    "            #structureList[i][2]=='走'\n",
    "            \n",
    "        \n",
    "        #动作规范\n",
    "        #if \"停\" in structureList[i][2]:\n",
    "            #structureList[i][2]=\"停\"\n",
    "        #elif \"头\" in structureList[i][2] or \"转身\" in structureList[i][2]:\n",
    "            #structureList[i][2]=\"掉头\"\n",
    "        #elif \"转\" in structureList[i][2] or \"拐\" in structureList[i][2]:\n",
    "            #structureList[i][2]=\"转\"\n",
    "        #elif \"退\" in structureList[i][2]:\n",
    "            #structureList[i][2]=\"退\"\n",
    "        #else:\n",
    "            #structureList[i][2]=\"走\"\n",
    "        #地名词中C400\n",
    "        begin=re.findall(r\"([A-Za-z]).*(\\d{3})\",structureList[i][0])\n",
    "        if begin != []:\n",
    "            structureList[i][0]=begin[0][0]+begin[0][1]\n",
    "        finish=re.findall(r\"([A-Za-z]).*(\\d{3})\",structureList[i][1])\n",
    "        if finish != []:\n",
    "            structureList[i][1]=finish[0][0]+finish[0][1]\n",
    "        #模糊速度规范\n",
    "        if re.match( r'(快|急|迅速|马上|立即)' ,structureList[i][5] ) != None:        \n",
    "            structureList[i][5]='加速'\n",
    "        elif \"慢\" in structureList[i][5] or \"缓\" in structureList[i][5]:\n",
    "            structureList[i][5]='减速'\n",
    "        #模糊距离规范\n",
    "        if \"点\" in structureList[i][4] or \"些\" in structureList[i][4]: \n",
    "            structureList[i][4]='1米'\n",
    "        if \"步\" in structureList[i][4]:\n",
    "            if filter(str.isdigit,structureList[i][4])!='':\n",
    "                structureList[i][4]=filter(str.isdigit,structureList[i][4]) + '米'\n",
    "            else:\n",
    "                structureList[i][4]='1米'\n",
    "#提取MDP需要的结构化指令，以及MDP各个状态元素的值            \n",
    "def stateextract(structureList,storelist,statelist):\n",
    "    if structureList[0][1]!='__':\n",
    "        storelist.append(structureList[0][1])\n",
    "        statelist.append(1)\n",
    "    else:\n",
    "        storelist.append(structureList[0][1])\n",
    "        statelist.append(0)\n",
    "    if structureList[0][2]!='__':\n",
    "        storelist.append(structureList[0][2])\n",
    "        statelist.append(1)\n",
    "    else:\n",
    "        storelist.append(structureList[0][2])\n",
    "        statelist.append(0)\n",
    "    if structureList[0][4]!='__':\n",
    "        storelist.append(structureList[0][4])\n",
    "        statelist.append(1)\n",
    "    else:\n",
    "        storelist.append(structureList[0][4])\n",
    "        statelist.append(0)\n",
    "    if structureList[0][5]!='__':\n",
    "        storelist.append(structureList[0][5])\n",
    "        statelist.append(1)\n",
    "    else:\n",
    "        storelist.append(structureList[0][5])\n",
    "        statelist.append(0)\n",
    "    if structureList[0][6]=='__':\n",
    "        storelist.append(structureList[0][6])\n",
    "        statelist.append(0)\n",
    "    elif structureList[0][6]=='AT':\n",
    "        storelist.append(structureList[0][6])\n",
    "        statelist.append(1)\n",
    "    elif structureList[0][6]=='NAT':\n",
    "        storelist.append(structureList[0][6])\n",
    "        statelist.append(2)\n",
    "\n",
    "def mdptrain(policy):\n",
    "#训练MDP模型P为转移概率矩阵，R为回报矩阵，一共81一个状态以此为速度、距离、动作、终点组成。    \n",
    "    \n",
    "    P = ones( (10,144,144) )/144\n",
    "    #R = array( [ [100,0,0,0,0], [100,0,0,0,-100], [100,0,0,0,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100], [0,0,100,0,0], [0,0,0,0,200], [0,100,0,100,-100] ] )\n",
    "    \n",
    "    R = array( [[50,-10,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,50,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,-10,50,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,50,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,50,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,-10,-10,50,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,50,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,50,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,50,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,50,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,-10,50,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,50,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,50,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,-10,-10,-10,-10,-10,50,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,50,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,50,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,50,-10,-10], [-10,-10,-10,-10,-10,50,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,50,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,50,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,50,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,50,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,50,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,50,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,50,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,50,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,-10,50,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,50,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,50,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,-10,-10,50,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,50,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,50,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,50,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,50,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,-10,50,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,50,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,50,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,-10,200], [-10,-10,-10,-10,-10,-10,-10,50,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,50,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,50,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,50,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,50,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,50,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,50,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,50,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,50,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,50,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,50,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,-10,-10,50,-10], [-10,-10,-10,-10,-10,-10,50,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,50,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,50,-10,-10,-10], [-10,50,-10,-10,-10,-10,-10,-10,-10,-10], [-10,-10,-10,-10,-10,-10,50,-10,-10,-10]] )\n",
    "    vi = mdptoolbox.mdp.RelativeValueIteration(P, R)\n",
    "    #vi = mdptoolbox.mdp.ValueIteration(P, R, 0.95)\n",
    "    vi.verbose\n",
    "    vi.run()\n",
    "    policy+=list(vi.policy)\n",
    "\n",
    "'''def policycs(policy,statelist,policy_c,storelist):\n",
    "    state_c=(statelist[0]*2**3+statelist[1]*2**2+statelist[2]*2**1+statelist[3])*3+statelist[4]\n",
    "    print policy[state_c]\n",
    "    if policy[state_c]==0:\n",
    "        policy_c[0]='提示'\n",
    "    elif policy[state_c]==1:\n",
    "        policy_c[0]='再提示'\n",
    "    elif policy[state_c]==2:\n",
    "        policy_c[0]='确认'\n",
    "    elif policy[state_c]==3:\n",
    "        policy_c[0]='再确认'\n",
    "    elif policy[state_c]==4:\n",
    "        policy_c[0]='完成'\n",
    "    for i in range(len(storelist)):\n",
    "        if storelist[i]!='__':\n",
    "            policy_c[0]+=storelist[i]\n",
    "    print state_c\n",
    "    print policy_c[0]'''\n",
    "def store(storelist,laststore,statelist):\n",
    "#非否定情况下保存下来的历史信息与当前信息的融合\n",
    "    if laststore[0]!='__' and storelist[0]=='__':\n",
    "        storelist[0]=laststore[0]\n",
    "        statelist[0]=1\n",
    "    if laststore[1]!='__' and storelist[1]=='__':\n",
    "        storelist[1]=laststore[1]\n",
    "        statelist[1]=1\n",
    "    if laststore[2]!='__' and storelist[2]=='__':\n",
    "        storelist[2]=laststore[2]\n",
    "        statelist[2]=1\n",
    "    if laststore[3]!='__' and storelist[3]=='__':\n",
    "        storelist[3]=laststore[3]\n",
    "        statelist[3]=1\n",
    "    #elif laststore[4]!='__' and storelist[4]=='__':\n",
    "        #storelist[4]=laststore[4]\n",
    "        #if storelist[4]]\n",
    "def natstore(storelist,laststore,statelist):\n",
    "#否定情况下保存下来的历史信息与当前信息的融合\n",
    "    if laststore[0]!='__' and storelist[0]=='__' and (storelist[1]!='__' or storelist[2]!='__' or storelist[3]!='__') :\n",
    "        storelist[0]=laststore[0]\n",
    "        statelist[0]=1\n",
    "    if laststore[1]!='__' and storelist[1]=='__' and (storelist[0]!='__' or storelist[2]!='__' or storelist[3]!='__') :\n",
    "        storelist[1]=laststore[1]\n",
    "        statelist[1]=1\n",
    "    if laststore[2]!='__' and storelist[2]=='__' and (storelist[0]!='__' or storelist[1]!='__' or storelist[3]!='__') :\n",
    "        storelist[2]=laststore[2]\n",
    "        statelist[2]=1\n",
    "    if laststore[3]!='__' and storelist[3]=='__' and (storelist[0]!='__' or storelist[1]!='__' or storelist[2]!='__') :\n",
    "        storelist[3]=laststore[3]\n",
    "        statelist[3]=1\n",
    "def changes(statelist):\n",
    "    if statelist[4]==1:\n",
    "        for j in range(4):\n",
    "            if statelist[j]!=0:\n",
    "                statelist[j]=2\n",
    "\n",
    "def policycs(policy,statelist,policy_c,storelist):\n",
    "    state_c=statelist[0]*3*3*4+statelist[1]*3*3+statelist[2]*3+statelist[3]\n",
    "    if policy[state_c]==0:\n",
    "        policy_c[0]='提示'\n",
    "    elif policy[state_c]==1:\n",
    "        policy_c[0]='总确认'\n",
    "        for i in range(4):\n",
    "            if storelist[i]!='__':\n",
    "                policy_c[0]+=storelist[i]\n",
    "    elif policy[state_c]==2:\n",
    "        policy_c[0]='速度确认'\n",
    "        policy_c[0]+=storelist[3]\n",
    "    elif policy[state_c]==3:\n",
    "        policy_c[0]='距离确认'\n",
    "        policy_c[0]+=storelist[2]\n",
    "    elif policy[state_c]==4:\n",
    "        policy_c[0]='动作确认'\n",
    "        policy_c[0]+=storelist[1]\n",
    "    elif policy[state_c]==5:\n",
    "        policy_c[0]='目的确认'\n",
    "        policy_c[0]+=storelist[0]\n",
    "    elif policy[state_c]==6:\n",
    "        policy_c[0]='未收录项目总确认'\n",
    "        for i in range(4):\n",
    "            if storelist[i]!='__':\n",
    "                policy_c[0]+=storelist[i]\n",
    "    elif policy[state_c]==7:\n",
    "        policy_c[0]='未收录动作确认'\n",
    "        policy_c[0]+=storelist[1]\n",
    "    elif policy[state_c]==8:\n",
    "        policy_c[0]='未收录目的确认'\n",
    "        policy_c[0]+=storelist[0]\n",
    "    elif policy[state_c]==9:\n",
    "        policy_c[0]='完成'\n",
    "        for i in range(4):\n",
    "            if storelist[i]!='__':\n",
    "                policy_c[0]+=storelist[i]\n",
    "    print policy_c[0],state_c\n",
    "\n",
    "def loc(structureList,statelist,storelist):\n",
    "    f6=open('location')\n",
    "    Location=f6.readlines()\n",
    "    structureList[0][1]=structureList[0][1].decode('utf-8')\n",
    "    sum1=[0]*len(Location)\n",
    "    if structureList[0][1]!=u'__':\n",
    "        if statelist[0]==1:\n",
    "            for i in range(len(Location)):\n",
    "                Location[i]=Location[i].replace('\\n',\"\").decode('utf-8')\n",
    "                if Location[i]==structureList[0][1]:\n",
    "                    statelist[0]=1\n",
    "                    break\n",
    "                else:\n",
    "                    statelist[0]=3\n",
    "                    \n",
    "            if statelist[0]==3:\n",
    "                for j in range(len(Location)):\n",
    "                    for k in range(min(len(Location[j]),len(structureList[0][1]))):\n",
    "                        if Location[j][k]==structureList[0][1][k]:\n",
    "                            sum1[j]=sum1[j]+1\n",
    "                            \n",
    "                if max(sum1)!=0:\n",
    "                    index1=sum1.index(max(sum1))\n",
    "                    storelist[0]=Location[index1].encode('utf-8')\n",
    "                    statelist[0]=1\n",
    "                else:\n",
    "                    storelist[0]=\"无匹配\"\n",
    "        \n",
    "def act(structureList,statelist,storelist):\n",
    "    f7=open('action')\n",
    "    Action=f7.readlines()\n",
    "    structureList[0][2]=structureList[0][2].decode('utf-8')\n",
    "    sum2=[0]*len(Action)\n",
    "    if structureList[0][2]!=u'__':\n",
    "        if statelist[1]==1:\n",
    "            for i in range(len(Action)):\n",
    "                Action[i]=Action[i].replace('\\n',\"\").decode('utf-8')\n",
    "                if Action[i]==structureList[0][2]:\n",
    "                    statelist[1]=1\n",
    "                    break\n",
    "                else:\n",
    "                    statelist[1]=3\n",
    "                    \n",
    "            if statelist[1]==3:\n",
    "                for j in range(len(Action)):\n",
    "                    for k in range(min(len(Action[j]),len(structureList[0][2]))):\n",
    "                        if Action[j][k]==structureList[0][2][k]:\n",
    "                            sum2[j]=sum2[j]+1\n",
    "                    \n",
    "                if max(sum2)!=0:\n",
    "                    index2=sum2.index(max(sum2))\n",
    "                    storelist[1]=Action[index2].encode('utf-8')\n",
    "                    statelist[1]=1\n",
    "                else:\n",
    "                    storelist[1]=\"无匹配\"\n",
    "\n",
    "                    \n",
    "def testAll():\n",
    "    policy=[]\n",
    "    mdptrain(policy)\n",
    "    laststore=['__']*5\n",
    "    while distinguishWord():\n",
    "        semanticTest()\n",
    "        merge()\n",
    "        \n",
    "        splitTest()\n",
    "        startFinishTest()\n",
    "        save()\n",
    "        structureList=extract('startFinishOutput')\n",
    "        fillElement(structureList)\n",
    "        for structure in structureList:\n",
    "            print ','.join(structure)\n",
    "        \n",
    "        liststructure=[]\n",
    "        liststructure=structureList\n",
    "        respond=[]\n",
    "        allrespond=\"\"\n",
    "        print liststructure,len(liststructure)\n",
    "        for i in range(len(liststructure)):\n",
    "            print liststructure[i]\n",
    "            structureList=[[]]\n",
    "            structureList[0]=liststructure[i]\n",
    "            storelist=[]\n",
    "            statelist=[]\n",
    "            policy_c=['']\n",
    "            stateextract(structureList,storelist,statelist)\n",
    "        \n",
    "            if storelist[4]!='NAT':\n",
    "                store(storelist,laststore,statelist)\n",
    "            #print statelist\n",
    "            else:\n",
    "                natstore(storelist,laststore,statelist)\n",
    "            \n",
    "            loc(structureList,statelist,storelist)\n",
    "            act(structureList,statelist,storelist)\n",
    "            changes(statelist)\n",
    "            laststore=storelist\n",
    "            print statelist\n",
    "            print \"进入for循环\"\n",
    "            \n",
    "            if storelist[0]==\"无匹配\" or storelist[1]==\"无匹配\":\n",
    "                print \"目的地与动作相关无匹配项目，请重新输入指令！\"\n",
    "            \n",
    "                while distinguishWord():\n",
    "                    semanticTest()\n",
    "                    merge()\n",
    "\n",
    "                    splitTest()\n",
    "                    startFinishTest()\n",
    "                    save()\n",
    "                    structureList=extract('startFinishOutput')\n",
    "                    fillElement(structureList)\n",
    "                    for structure in structureList:\n",
    "                        print ','.join(structure)\n",
    "                    \n",
    "                \n",
    "                    storelist=[]\n",
    "                    statelist=[]\n",
    "                    policy_c=['']\n",
    "                    stateextract(structureList,storelist,statelist)\n",
    "        \n",
    "                    if storelist[4]!='NAT':\n",
    "                        store(storelist,laststore,statelist)\n",
    "                    #print statelist\n",
    "                    else:\n",
    "                        natstore(storelist,laststore,statelist)\n",
    "        \n",
    "        \n",
    "                    loc(structureList,statelist,storelist)\n",
    "                    act(structureList,statelist,storelist)\n",
    "                    changes(statelist)\n",
    "                    laststore=storelist\n",
    "                    print statelist\n",
    "                    print \"不匹配分支\"\n",
    "                    if storelist[0]==\"无匹配\" or storelist[1]==\"无匹配\":\n",
    "                        print \"目的地与动作相关无匹配项目，请重新输入指令！\"\n",
    "                        continue\n",
    "                    \n",
    "                    else:\n",
    "\n",
    "                        policycs(policy,statelist,policy_c,storelist)\n",
    "    \n",
    "                        k = aiml.Kernel()\n",
    "                        k.learn(\"cn-startup.xml\")\n",
    "                        k.respond(\"load aiml cn\")\n",
    "                \n",
    "                    if '完成' in policy_c[0]:\n",
    "                        laststore=['__']*5\n",
    "                        respond.append(k.respond(policy_c[0]))\n",
    "                        print \"不匹配分支完成\"\n",
    "                        break\n",
    "                    else:\n",
    "                        print k.respond(policy_c[0])\n",
    "                        print \"不匹配分支继续运行\"\n",
    "\n",
    "            else:\n",
    "                policycs(policy,statelist,policy_c,storelist)\n",
    "    \n",
    "                k = aiml.Kernel()\n",
    "                k.learn(\"cn-startup.xml\")\n",
    "                k.respond(\"load aiml cn\")\n",
    "                print k.respond(policy_c[0])\n",
    "                \n",
    "                while distinguishWord():\n",
    "                    semanticTest()\n",
    "                    merge()\n",
    "\n",
    "                    splitTest()\n",
    "                    startFinishTest()\n",
    "                    save()\n",
    "                    structureList=extract('startFinishOutput')\n",
    "                    fillElement(structureList)\n",
    "                    for structure in structureList:\n",
    "                        print ','.join(structure)\n",
    "                    \n",
    "                  \n",
    "                    storelist=[]\n",
    "                    statelist=[]\n",
    "                    policy_c=['']\n",
    "                    stateextract(structureList,storelist,statelist)\n",
    "\n",
    "                    print storelist,statelist\n",
    "                    if storelist[4]!='NAT':\n",
    "                        store(storelist,laststore,statelist)\n",
    "                    #print statelist\n",
    "                    else:\n",
    "                        natstore(storelist,laststore,statelist)\n",
    "        \n",
    "        \n",
    "                    loc(structureList,statelist,storelist)\n",
    "                    act(structureList,statelist,storelist)\n",
    "                    changes(statelist)\n",
    "                    laststore=storelist\n",
    "                    print statelist\n",
    "                    print \"匹配分支\"\n",
    "                    if storelist[0]==\"无匹配\" or storelist[1]==\"无匹配\":\n",
    "                        print \"目的地与动作相关无匹配项目，请重新输入指令！\"\n",
    "                        continue\n",
    "                    else:\n",
    "                        policycs(policy,statelist,policy_c,storelist)\n",
    "    \n",
    "                        k = aiml.Kernel()\n",
    "                        k.learn(\"cn-startup.xml\")\n",
    "                        k.respond(\"load aiml cn\")\n",
    "                    \n",
    "                    if '完成' in policy_c[0]:\n",
    "                        laststore=['__']*5\n",
    "                        respond.append(k.respond(policy_c[0]))\n",
    "                        print \"匹配分支完成\"\n",
    "                        break\n",
    "                    else:\n",
    "                        print k.respond(policy_c[0])\n",
    "                        print \"匹配分支未完成\"\n",
    "        for j in range(len(respond)):\n",
    "            respond[j]=respond[j].lstrip('好的，')\n",
    "            if j!=0:\n",
    "                respond[j]=\"然后\" + respond[j]\n",
    "            allrespond=allrespond + respond[j]\n",
    "        print \"好的，\" + allrespond       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入命令：走到a503\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    testAll()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s=[\"一张照片\",\"吃饭了\"]\n",
    "if \"照片\" in s[0]:\n",
    "    s[0]=1\n",
    "print s[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "s=[1,\"一张照片\"]\n",
    "if sentence1=re.match( r'(快|急|迅速|马上|立即)' ,structureList[i][5] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=raw_input(\"你还是请输入\".decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åå\n"
     ]
    }
   ],
   "source": [
    "print u\"\\xe5\\x90\\x91\\xe5\\x89\\x8d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "������\n"
     ]
    }
   ],
   "source": [
    "s = \"哈哈哈\"\n",
    "print (s.decode('utf-8')).encode('gb2312')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哈哈哈\n"
     ]
    }
   ],
   "source": [
    "s = \"哈哈哈\"\n",
    "print s.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
